{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "999e2c2a-630b-478a-a5c0-cbcbe6577e07",
   "metadata": {},
   "source": [
    "# Language Detection using Lingua-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d5f55-34ec-4d4f-a5da-ebe3fcbe1f36",
   "metadata": {},
   "source": [
    "<p>Language-py is a powerful python package because it does not require any connection to an API. Additionally it doesn't use heavy-duty neural networks and has good performance on short texts (perfect for chat messages). Also, since it is a python package it's easy to include in our requirements.txt file. As long as it's maintained we should be in good shape!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297101f5-0d3f-4f22-820a-b226a657bc98",
   "metadata": {},
   "source": [
    "<p>Let's load the packages we need, and load the dataframe that contains the data from our parsed .txt files</p>\n",
    "<p>Make sure to ad your text files to the \"DROP_TXT_HERE\" folder and then run the app.py script from the command prompt</p>\n",
    "Run:\n",
    "\n",
    "```bash\n",
    "python app.py --process\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc470840-b385-425b-85fb-d36f10b6c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from lingua import LanguageDetectorBuilder, Language\n",
    "\n",
    "df = pd.read_hdf(os.path.join(os.getcwd(),\"vis\",\"data.h5\"))\n",
    "languages = [Language.ENGLISH, Language.FRENCH, Language.GERMAN, Language.SPANISH, Language.ITALIAN]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8a6476-f94c-465d-8909-4fac05a64080",
   "metadata": {},
   "source": [
    "Lingua-py offers a low-detection mode that saves on memory and process time at the cost of accurate language detection. We'll compare the detection performance between \n",
    "1. a subset of european languages (they represent the bulk of the languages spoken in this sample dataset) and\n",
    "2. the full lingua-py atlas (75 languages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "405f32f8-deda-47a1-92bb-509e933debb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOW_ACCURACY = True\n",
    "DETECT_ALL_LANGUAGES = False\n",
    "if LOW_ACCURACY:\n",
    "    if DETECT_ALL_LANGUAGES:\n",
    "        detector = LanguageDetectorBuilder.from_all_languages().with_low_accuracy_mode().build()\n",
    "    else:\n",
    "        detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
    "else:\n",
    "    if DETECT_ALL_LANGUAGES:\n",
    "        detector = LanguageDetectorBuilder.from_all_languages().with_low_accuracy_mode().build()\n",
    "    else:\n",
    "        detector = LanguageDetectorBuilder.from_languages(*languages).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb0d8b9-b650-4b3f-8ba1-1b7e63327df4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'languages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m _languages = [\u001b[38;5;28mgetattr\u001b[39m(Language, k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m languages]\n\u001b[32m      2\u001b[39m detector = LanguageDetectorBuilder.from_languages(*_languages).build()\n\u001b[32m      3\u001b[39m langs = subset.Message.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x:detector.detect_language_of(x))\n",
      "\u001b[31mNameError\u001b[39m: name 'languages' is not defined"
     ]
    }
   ],
   "source": [
    "_languages = [getattr(Language, k) for k in languages]\n",
    "detector = LanguageDetectorBuilder.from_languages(*_languages).build()\n",
    "langs = subset.Message.apply(lambda x:detector.detect_language_of(x))\n",
    "langs = langs.apply(lambda x:x.name if x is not None else None)\n",
    "# pd.concat((subset,langs),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a632aa9-5189-4a4a-be63-434edeb0e708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
